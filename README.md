## TFModelQuantizer

A package which converts saved models weights to quantized FP32 ,FP16 and INT8 for faster Inference through TF-TensorRT. A demonstration of the package on Resnet-50 is provided in the [Colab Notebook](https://colab.research.google.com/drive/1CDKGzLtt2Zy51TWt4bRQou3i7Mvy_THa?usp=sharing)